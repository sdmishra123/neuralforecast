{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1b0298",
   "metadata": {},
   "source": [
    "# 1. Installing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58bee7-e771-43f8-a137-af9f6561f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.tsmixer.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70361bb-d4e5-4687-807e-2f32d7483dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neuralforecast in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (1.6.4)\n",
      "Requirement already satisfied: datasetsforecast in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (0.0.8)\n",
      "Requirement already satisfied: coreforecast>=0.0.3 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from neuralforecast) (0.0.3)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from neuralforecast) (1.26.3)\n",
      "Requirement already satisfied: pandas>=1.3.5 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from neuralforecast) (2.2.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from neuralforecast) (2.2.0)\n",
      "Requirement already satisfied: pytorch-lightning>=2.0.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from neuralforecast) (2.1.3)\n",
      "Requirement already satisfied: ray>=2.2.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray[tune]>=2.2.0->neuralforecast) (2.9.1)\n",
      "Requirement already satisfied: optuna in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from neuralforecast) (3.5.0)\n",
      "Requirement already satisfied: utilsforecast>=0.0.25 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from neuralforecast) (0.0.26)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from datasetsforecast) (3.9.3)\n",
      "Requirement already satisfied: fugue>=0.8.1 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from datasetsforecast) (0.8.7)\n",
      "Requirement already satisfied: numba in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from datasetsforecast) (0.59.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from datasetsforecast) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from datasetsforecast) (4.66.1)\n",
      "Requirement already satisfied: xlrd>=1.0.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from datasetsforecast) (2.0.1)\n",
      "Requirement already satisfied: triad>=0.9.3 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fugue>=0.8.1->datasetsforecast) (0.9.5)\n",
      "Requirement already satisfied: adagio>=0.2.4 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fugue>=0.8.1->datasetsforecast) (0.2.4)\n",
      "Requirement already satisfied: qpd>=0.4.4 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fugue>=0.8.1->datasetsforecast) (0.4.4)\n",
      "Requirement already satisfied: fugue-sql-antlr>=0.1.6 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fugue>=0.8.1->datasetsforecast) (0.2.0)\n",
      "Requirement already satisfied: sqlglot in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fugue>=0.8.1->datasetsforecast) (20.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fugue>=0.8.1->datasetsforecast) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pandas>=1.3.5->neuralforecast) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pandas>=1.3.5->neuralforecast) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pandas>=1.3.5->neuralforecast) (2023.4)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (2023.12.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (1.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.9.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from pytorch-lightning>=2.0.0->neuralforecast) (0.10.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (4.21.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (1.0.7)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (4.23.4)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=6.0.1 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from ray[tune]>=2.2.0->neuralforecast) (6.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from torch>=2.0.0->neuralforecast) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from torch>=2.0.0->neuralforecast) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from tqdm->datasetsforecast) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from aiohttp->datasetsforecast) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from aiohttp->datasetsforecast) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from aiohttp->datasetsforecast) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from aiohttp->datasetsforecast) (4.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from numba->datasetsforecast) (0.42.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from optuna->neuralforecast) (1.13.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from optuna->neuralforecast) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from optuna->neuralforecast) (2.0.25)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from requests->datasetsforecast) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from requests->datasetsforecast) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from requests->datasetsforecast) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from requests->datasetsforecast) (2024.2.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from alembic>=1.5.0->optuna->neuralforecast) (1.3.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime<4.12 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fugue-sql-antlr>=0.1.6->fugue>=0.8.1->datasetsforecast) (4.11.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=2.0.0->neuralforecast) (69.0.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->neuralforecast) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna->neuralforecast) (3.0.3)\n",
      "Requirement already satisfied: fs in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from triad>=0.9.3->fugue>=0.8.1->datasetsforecast) (2.4.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from jinja2->fugue>=0.8.1->datasetsforecast) (2.1.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (0.17.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in c:\\users\\dhavy\\.conda\\envs\\neuralforecast\\lib\\site-packages (from fs->triad>=0.9.3->fugue>=0.8.1->datasetsforecast) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "!pip install neuralforecast datasetsforecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef6532",
   "metadata": {},
   "source": [
    "# 2. Load ETTm2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec5b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhavy\\AppData\\Local\\Temp\\ipykernel_22140\\156242825.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was too old on your system - pyarrow 10.0.1 is the current minimum supported version as of this release.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "from datasetsforecast.long_horizon import LongHorizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5965c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57600\n",
      "11520 11520\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# Change this to your own data to try the model\n",
    "Y_df, _, _ = LongHorizon.load(directory='./', group='ETTm2')\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "\n",
    "n_time = len(Y_df.ds.unique())\n",
    "print(n_time)\n",
    "val_size = int(.2 * n_time)\n",
    "test_size = int(.2 * n_time)\n",
    "val_size=val_size\n",
    "test_size=test_size\n",
    "print(val_size,test_size)\n",
    "\n",
    "# Y_df.groupby('unique_id').head(2)\n",
    "\n",
    "# Y_df.unique_id.unique()\n",
    "# result = Y_df.groupby('unique_id')['ds'].value_counts().groupby('unique_id').count()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f9be9",
   "metadata": {},
   "source": [
    "# 3. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e33fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Sapna\\Nixtla_Project\\neuralforecast\\neuralforecast\\utils.py:281: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AirPassengersPanel[\"y_[lag12]\"].fillna(AirPassengersPanel[\"y\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import Informer, Autoformer, FEDformer, PatchTST, TSMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503784d-044a-45ee-acb3-4ddb4b4e4959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "horizon  = 12\n",
    "n_series = len(Y_df.unique_id.unique())\n",
    "n_block  = 1\n",
    "ff_dim   = 16\n",
    "target_slice = slice(0,2)\n",
    "# print(type(n_series),n_series)\n",
    "\n",
    "models = [TSMixer(h=horizon,\n",
    "                input_size=horizon,\n",
    "                # max_steps=1000,\n",
    "                # val_check_steps=100,\n",
    "                # early_stop_patience_steps=3,\n",
    "                n_series=n_series,\n",
    "                n_block=n_block,\n",
    "                ff_dim=ff_dim,\n",
    "                target_slice = None)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb93f18-d6d2-4fd7-b55d-d6565444462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "nf = NeuralForecast(\n",
    "    models=models,\n",
    "    freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d1211-1867-4988-8b1d-f0ffa8c9f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063a6bb514ca41cda809888104b0f529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084a3469ee2f4faeaa40daa824d8abdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "Y_hat_df = nf.cross_validation(df=Y_df,\n",
    "                               val_size=val_size,\n",
    "                               test_size=test_size,\n",
    "                               n_windows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269f35a-616c-4741-9a58-f9a821d762af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>TSMixer</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:00:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.509198</td>\n",
       "      <td>-0.977673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:15:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.495635</td>\n",
       "      <td>-0.865620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:30:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.620860</td>\n",
       "      <td>-0.961624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:45:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.554487</td>\n",
       "      <td>-1.049700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 01:00:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.381059</td>\n",
       "      <td>-0.953600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ds              cutoff   TSMixer         y\n",
       "unique_id                                                            \n",
       "HUFL      2017-10-24 00:00:00 2017-10-23 23:45:00 -0.509198 -0.977673\n",
       "HUFL      2017-10-24 00:15:00 2017-10-23 23:45:00 -0.495635 -0.865620\n",
       "HUFL      2017-10-24 00:30:00 2017-10-23 23:45:00 -0.620860 -0.961624\n",
       "HUFL      2017-10-24 00:45:00 2017-10-23 23:45:00 -0.554487 -1.049700\n",
       "HUFL      2017-10-24 01:00:00 2017-10-23 23:45:00 -0.381059 -0.953600"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "Y_hat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa464bbb",
   "metadata": {},
   "source": [
    "# 4. Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a16d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>TSMixer</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:00:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.509198</td>\n",
       "      <td>-0.977673</td>\n",
       "      <td>HUFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:15:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.495635</td>\n",
       "      <td>-0.865620</td>\n",
       "      <td>HUFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:30:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.620860</td>\n",
       "      <td>-0.961624</td>\n",
       "      <td>HUFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 00:45:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.554487</td>\n",
       "      <td>-1.049700</td>\n",
       "      <td>HUFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUFL</th>\n",
       "      <td>2017-10-24 01:00:00</td>\n",
       "      <td>2017-10-23 23:45:00</td>\n",
       "      <td>-0.381059</td>\n",
       "      <td>-0.953600</td>\n",
       "      <td>HUFL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ds              cutoff   TSMixer         y  \\\n",
       "unique_id                                                               \n",
       "HUFL      2017-10-24 00:00:00 2017-10-23 23:45:00 -0.509198 -0.977673   \n",
       "HUFL      2017-10-24 00:15:00 2017-10-23 23:45:00 -0.495635 -0.865620   \n",
       "HUFL      2017-10-24 00:30:00 2017-10-23 23:45:00 -0.620860 -0.961624   \n",
       "HUFL      2017-10-24 00:45:00 2017-10-23 23:45:00 -0.554487 -1.049700   \n",
       "HUFL      2017-10-24 01:00:00 2017-10-23 23:45:00 -0.381059 -0.953600   \n",
       "\n",
       "          unique_id  \n",
       "unique_id            \n",
       "HUFL           HUFL  \n",
       "HUFL           HUFL  \n",
       "HUFL           HUFL  \n",
       "HUFL           HUFL  \n",
       "HUFL           HUFL  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "import matplotlib.pyplot as plt\n",
    "Y_hat_df_v1 = Y_hat_df.reset_index(drop=False).drop(columns=['unique_id','ds','cutoff','TSMixer','y'])\n",
    "Y_hat_df_v1 = Y_hat_df\n",
    "Y_hat_df_v1['unique_id'] = Y_hat_df_v1.index\n",
    "Y_hat_df_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1db0fd-816c-4ff2-90bf-a04e2ff4f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-20 23:45:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57534"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "Y_hat_df_v1['ds'] = pd.to_datetime(Y_hat_df_v1['ds'])\n",
    "max_date = Y_hat_df_v1['ds'].max()\n",
    "print(max_date)\n",
    "\n",
    "Y_hat_df_v2 = Y_hat_df_v1[Y_hat_df_v1[\"ds\"] >= \"2018-01-01 23:45:50\"]\n",
    "len(Y_hat_df_v2[Y_hat_df_v2['unique_id']=='OT'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7ed40",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.5 GiB for an array with shape (2621440000,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m Y_plot \u001b[38;5;241m=\u001b[39m Y_hat_df_v2[Y_hat_df_v2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# OT dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m cutoffs \u001b[38;5;241m=\u001b[39m Y_hat_df_v2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcutoff\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()[::horizon]\n\u001b[1;32m----> 3\u001b[0m Y_plot \u001b[38;5;241m=\u001b[39m \u001b[43mY_plot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mY_hat_df_v2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcutoff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcutoffs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(Y_plot[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m], Y_plot[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuralforecast\\lib\\site-packages\\pandas\\core\\frame.py:4081\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4079\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4083\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4084\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4085\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuralforecast\\lib\\site-packages\\pandas\\core\\frame.py:4137\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4133\u001b[0m     )\n\u001b[0;32m   4135\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[1;32m-> 4137\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   4140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuralforecast\\lib\\site-packages\\pandas\\core\\indexing.py:2653\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2651\u001b[0m result \u001b[38;5;241m=\u001b[39m key\n\u001b[0;32m   2652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, ABCSeries) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mequals(index):\n\u001b[1;32m-> 2653\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[0;32m   2656\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2657\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2658\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2659\u001b[0m         )\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuralforecast\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6182\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m   6181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer(target)\n\u001b[1;32m-> 6182\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuralforecast\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6158\u001b[0m, in \u001b[0;36mIndex.get_indexer_non_unique\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6156\u001b[0m     tgt_values \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_get_engine_target()\n\u001b[1;32m-> 6158\u001b[0m indexer, missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer_non_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer), ensure_platform_int(missing)\n",
      "File \u001b[1;32mindex.pyx:461\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer_non_unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\neuralforecast\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1482\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(a, new_shape)\u001b[0m\n\u001b[0;32m   1479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros_like(a, shape\u001b[38;5;241m=\u001b[39mnew_shape)\n\u001b[0;32m   1481\u001b[0m repeats \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m-\u001b[39mnew_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m a\u001b[38;5;241m.\u001b[39msize)  \u001b[38;5;66;03m# ceil division\u001b[39;00m\n\u001b[1;32m-> 1482\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m)\u001b[49m[:new_size]\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reshape(a, new_shape)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 19.5 GiB for an array with shape (2621440000,) and data type int64"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "Y_plot = Y_hat_df_v2[Y_hat_df_v2['unique_id']=='OT'] # OT dataset\n",
    "cutoffs = Y_hat_df_v2['cutoff'].unique()[::horizon]\n",
    "Y_plot = Y_plot[Y_hat_df_v2['cutoff'].isin(cutoffs)]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(Y_plot['ds'], Y_plot['y'], label='True')\n",
    "# plt.plot(Y_plot['ds'], Y_plot['Informer'], label='Informer')\n",
    "# plt.plot(Y_plot['ds'], Y_plot['Autoformer'], label='Autoformer')\n",
    "# plt.plot(Y_plot['ds'], Y_plot['PatchTST'], label='PatchTST')\n",
    "plt.plot(Y_plot['ds'], Y_plot['TSMixer'], label='TSMixer')\n",
    "plt.xlabel('Datestamp')\n",
    "plt.ylabel('OT')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89cda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from neuralforecast.losses.numpy import mae,mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSMixer: 0.353\n",
      "TSMixer: 2.179\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# mae_informer = mae(Y_hat_df['y'], Y_hat_df['Informer'])\n",
    "# mae_autoformer = mae(Y_hat_df['y'], Y_hat_df['Autoformer'])\n",
    "# mae_patchtst = mae(Y_hat_df['y'], Y_hat_df['PatchTST'])\n",
    "mae_tsmixer = mae(Y_hat_df['y'], Y_hat_df['TSMixer'])\n",
    "mape_tsmixer = mape(Y_hat_df['y'], Y_hat_df['TSMixer'])\n",
    "\n",
    "# print(f'Informer: {mae_informer:.3f}')\n",
    "# print(f'Autoformer: {mae_autoformer:.3f}')\n",
    "# print(f'PatchTST: {mae_patchtst:.3f}')\n",
    "print(f'TSMixer MAE: {mae_tsmixer:.3f}')\n",
    "print(f'TSMixer MAPE: {mape_tsmixer:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1838d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc1257-7529-476d-9c5b-9c7cb80ce644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
